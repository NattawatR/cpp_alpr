
//opencv
#include "opencv2/imgcodecs.hpp"
#include "opencv2/video/tracking.hpp"
#include "opencv2/imgproc.hpp"
#include "opencv2/videoio.hpp"
#include <opencv2/highgui.hpp>
#include <opencv2/video.hpp>
#include "opencv2/objdetect/objdetect.hpp"

//C++
#include <iostream>
#include <sstream>

#include "package_bgs/PBAS/PixelBasedAdaptiveSegmenter.h"
#include "package_tracking/BlobTracking.h"
#include "package_analysis/VehicleCouting.h"

using namespace cv;
using namespace std;

// Global variables
Mat frame, grayFrame;            //current frame
Mat fgMaskMOG2, k;               //fg mask fg mask generated by MOG2 method
Ptr<BackgroundSubtractor> pMOG2; //MOG2 Background subtractor
int keyboard;                    //input from keyboard

int morph_elem = 1;
int morph_size = 3;
int morph_operator = 1;
int const max_operator = 4;
int const max_elem = 2;
int const max_kernel_size = 21;
string window_name = "FG Mask MOG 2";
Rect region_of_interest = Rect(20, 300, 680, 200);

Mat flow, cflow;
UMat gray, prevgray, uflow;

//string car_cascade_name = "cars.xml";
//CascadeClassifier car_cascade;

//Edge
int scale = 1;
int delta = 0;
int ddepth = CV_16S;

Mat grad_x, grad_y;
Mat abs_grad_x, abs_grad_y, grad;

//Init interface
void processVideo(string videoFilename);
void processImages(char *firstFrameFilename);
void Morphology_Operations();
void Morphology_Operations_2(int, void *);
static void drawOptFlowMap(const Mat &flow, Mat &cflowmap, int step, double, const Scalar &color);

string cars_cascade_name = "/home/kridsada/Documents/LicenPLateProject/cpp_alpr/cars.xml";
CascadeClassifier cars_cascade;

int main(int argc, char *argv[])
{
  //Load cascade
  if (!cars_cascade.load(cars_cascade_name))
  {
    printf("--(!)Error loading\n");
    return -1;
  };

  //create Background Subtractor objects
  pMOG2 = createBackgroundSubtractorMOG2(); //MOG2 approach

  processVideo("../test_videos/sample_vid.mp4");

  //destroy GUI windows
  destroyAllWindows();
  return EXIT_SUCCESS;
}

void processVideo(string videoFilename)
{
  //create the capture object
  VideoCapture capture(videoFilename);
  if (!capture.isOpened())
  {
    //error in opening the video input
    cerr << "Unable to open video file: " << videoFilename << endl;
    exit(EXIT_FAILURE);
  }
  //read input data. ESC or 'q' for quitting
  while ((char)keyboard != 'q' && (char)keyboard != 27)
  {
    //read the current frame
    if (!capture.read(frame))
    {
      cerr << "Unable to read next frame." << endl;
      cerr << "Exiting..." << endl;
      exit(EXIT_FAILURE);
    }

    //update the background model

    //Crop image
    frame = frame(region_of_interest);
    GaussianBlur(frame, frame, Size(3, 3), 0, 0, BORDER_DEFAULT);
    cvtColor(frame, fgMaskMOG2, CV_BGR2GRAY);

    /// Gradient X
    Sobel(fgMaskMOG2, grad_x, ddepth, 1, 0, 3, scale, delta, BORDER_DEFAULT);
    /// Gradient Y
    Sobel(fgMaskMOG2, grad_y, ddepth, 0, 1, 3, scale, delta, BORDER_DEFAULT);

    convertScaleAbs(grad_x, abs_grad_x);
    convertScaleAbs(grad_y, abs_grad_y);

    addWeighted(abs_grad_x, 0.8, abs_grad_y, 0.2, 0, grad);

    threshold(grad, grad, 230, 255, CV_THRESH_BINARY | CV_THRESH_OTSU);

    pMOG2->apply(grad, gray);

    if (!prevgray.empty())
    {
      calcOpticalFlowFarneback(prevgray, gray, uflow, 0.5, 3, 15, 3, 5, 1.2, 0);
      cvtColor(prevgray, cflow, COLOR_GRAY2BGR);
      uflow.copyTo(flow);
      drawOptFlowMap(flow, cflow, 16, 1.5, Scalar(0, 255, 0));
      imshow("flow", cflow);
    }

    swap(prevgray, gray);

    // if (!gray.empty())
    // {
    //   // Perform blob tracking
    //   /*blobTracking->process(img_input, img_mask, img_blob);

    //   // Perform vehicle counting
    //   vehicleCouting->setInput(img_blob);
    //   vehicleCouting->setTracks(blobTracking->getTracks());
    //   vehicleCouting->process();*/
    //   cv::imshow("Test", gray);
    // }
    /*
    vector<Rect> cars;
    //-- In each face, detect eyes
    cars_cascade.detectMultiScale(fgMaskMOG2, cars, 1.1, 2, 0 | CV_HAAR_SCALE_IMAGE, Size(30, 30));

    for (size_t j = 0; j < cars.size(); j++)
    {
      rectangle( fgMaskMOG2, Point( cars[j].x, cars[j].y ), Point( cars[j].x + cars[j].width, cars[j].y + cars[j].height), Scalar( 0, 55, 255 ), +1, 4 );  
      //Point center(eyes[j].x + eyes[j].width * 0.5,eyes[j].y + eyes[j].height * 0.5);
      //int radius = cvRound((eyes[j].width + eyes[j].height) * 0.25);
      //circle(fgMaskMOG2, center, radius, Scalar(255, 0, 0), 4, 8, 0);
    }*/

    //adaptiveThreshold(fgMaskMOG2, fgMaskMOG2, 255, CV_THRESH_BINARY, THRESH_BINARY, 5, 5);
    //threshold(fgMaskMOG2, fgMaskMOG2, 0, 255, CV_THRESH_BINARY | CV_THRESH_OTSU);
    //pMOG2->apply(fgMaskMOG2, fgMaskMOG2);

    /*cv::threshold(
        fgMaskMOG2,       //	Input	image
        fgMaskMOG2,       //	Result	image
        200,              //	Threshold	value
        255,              //	Max	value	for	upward	operations
        cv::THRESH_BINARY //	Threshold	type	to	use
        );*/

    /// Default start
    // Morphology_Operations();
    //Morphology_Operations_2(0, 0);

    //get the frame number and write it on the current frame
    /*stringstream ss;
    rectangle(frame, cv::Point(10, 2), cv::Point(100, 20),
              cv::Scalar(255, 255, 255), -1);
    ss << capture.get(CAP_PROP_POS_FRAMES);
    string frameNumberString = ss.str();
    putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
            FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));*/

    /*
    //Threshold
    cv::threshold(
        fgMaskMOG2,       //	Input	image
        fgMaskMOG2,       //	Result	image
        200,              //	Threshold	value
        255,              //	Max	value	for	upward	operations
        cv::THRESH_BINARY //	Threshold	type	to	use
        );

#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>
using namespace cv;
        
    /// Create Trackbar to select Morphology operation
    createTrackbar("Operator:\n 0: Opening - 1: Closing \n 2: Gradient - 3: Top Hat \n 4: Black Hat", window_name, &morph_operator, max_operator, Morphology_Operations_2);

    /// Create Trackbar to select kernel type
    createTrackbar("Element:\n 0: Rect - 1: Cross - 2: Ellipse", window_name,
                   &morph_elem, max_elem,
                   Morphology_Operations_2);
    /// Create Trackbar to choose kernel size
    createTrackbar("Kernel size:\n 2n +1", window_name,
                   &morph_size, max_kernel_size,
                   Morphology_Operations_2);

    /// Default start
    Morphology_Operations();
    Morphology_Operations_2(0, 0);

    // Get connected components and stats
    const int connectivity_8 = 8;
    Mat labels, stats, centroids;
    cout << "Show label values:" << endl;
    int nLabels = connectedComponentsWithStats(fgMaskMOG2, labels, stats, centroids, connectivity_8, CV_32S);

    cout << "Show label values:" << endl;
    int component1Pixel = labels.at<int>(150, 150);
    cout << "pixel at(150,150) = " << component1Pixel << endl;
    int component2Pixel = labels.at<int>(300, 550);

    // Statistics
    cout << "Show statistics and centroids:" << endl;
    cout << "stats:" << endl
         << "(left,top,width,height,area)" << endl
         << stats << endl
         << endl;
    cout << "centroids:" << endl
         << "(x, y)" << endl
         << centroids << endl
         << endl;

    // Print individual stats for component 1 (component 0 is background)
    cout << "Component 1 stats:" << endl;
    cout << "CC_STAT_LEFT   = " << stats.at<int>(1, CC_STAT_LEFT) << endl;
    cout << "CC_STAT_TOP    = " << stats.at<int>(1, CC_STAT_TOP) << endl;
    cout << "CC_STAT_WIDTH  = " << stats.at<int>(1, CC_STAT_WIDTH) << endl;
    cout << "CC_STAT_HEIGHT = " << stats.at<int>(1, CC_STAT_HEIGHT) << endl;
    cout << "CC_STAT_AREA   = " << stats.at<int>(1, CC_STAT_AREA) << endl;

    cout << "Number of connected components = " << nLabels << endl
         << endl;
    cout << "pixel at(300,550) = " << component2Pixel << endl
         << endl;

    // Create image with only component 2
    Mat only2;
    compare(labels, 40, only2, CMP_EQ);

    //show the current frame and the fg masks */
    //imshow("Frame", only2);
    // rectangle(fgMaskMOG2, Point(20, 300), Point(700, 450), Scalar(0, 55, 255), +1, 4);
    //imshow("Result Grad", grad);
    // imshow("Result", gray);
    //get the input from the keyboard
    keyboard = waitKey(30);
  }
  //delete capture object
  capture.release();
}

void processImages(char *fistFrameFilename)
{
  //read the first file of the sequence
  frame = imread(fistFrameFilename);
  if (frame.empty())
  {
    //error in opening the first image
    cerr << "Unable to open first image frame: " << fistFrameFilename << endl;
    exit(EXIT_FAILURE);
  }
  //current image filename
  string fn(fistFrameFilename);
  //read input data. ESC or 'q' for quitting
  while ((char)keyboard != 'q' && (char)keyboard != 27)
  {
    //update the background model
    pMOG2->apply(frame, fgMaskMOG2);
    GaussianBlur(frame, frame, Size(7, 7), 1.5, 1.5);
    //get the frame number and write it on the current frame
    size_t index = fn.find_last_of("/");
    if (index == string::npos)
    {
      index = fn.find_last_of("\\");
    }
    size_t index2 = fn.find_last_of(".");
    string prefix = fn.substr(0, index + 1);
    string suffix = fn.substr(index2);
    string frameNumberString = fn.substr(index + 1, index2 - index - 1);
    istringstream iss(frameNumberString);
    int frameNumber = 0;
    iss >> frameNumber;
    rectangle(frame, cv::Point(10, 2), cv::Point(100, 20),
              cv::Scalar(255, 255, 255), -1);
    putText(frame, frameNumberString.c_str(), cv::Point(15, 15),
            FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));
    //get the input from the keyboard
    keyboard = waitKey(30);
    //search for the next image in the sequence
    ostringstream oss;
    oss << (frameNumber + 1);
    string nextFrameNumberString = oss.str();
    string nextFrameFilename = prefix + nextFrameNumberString + suffix;
    //read the next frame
    frame = imread(nextFrameFilename);
    if (frame.empty())
    {
      //error in opening the next image in the sequence
      cerr << "Unable to open image frame: " << nextFrameFilename << endl;
      exit(EXIT_FAILURE);
    }
    //update the path of the current frame
    fn.assign(nextFrameFilename);
  }
}

/**
  * @function Morphology_Operations
  */
void Morphology_Operations()
{
  // Since MORPH_X : 2,3,4,5 and 6
  int operation = 1 + 2;

  Mat element = getStructuringElement(0, Size(2 * 3 + 1, 2 * 3 + 1), Point(5, 5));

  /// Apply the specified morphology operation
  morphologyEx(fgMaskMOG2, fgMaskMOG2, operation, element);
}

void Morphology_Operations_2(int, void *)
{
  // Since MORPH_X : 2,3,4,5 and 6
  int operation = 0 + 2;

  Mat element = getStructuringElement(1, Size(2 * 1 + 1, 2 * 1 + 1), Point(1, 1));

  /// Apply the specified morphology operation
  morphologyEx(fgMaskMOG2, fgMaskMOG2, operation, element);
}

static void drawOptFlowMap(const Mat &flow, Mat &cflowmap, int step,
                           double, const Scalar &color)
{
  for (int y = 0; y < cflowmap.rows; y += step)
    for (int x = 0; x < cflowmap.cols; x += step)
    {
      const Point2f &fxy = flow.at<Point2f>(y, x);
      line(cflowmap, Point(x, y), Point(cvRound(x + fxy.x), cvRound(y + fxy.y)),
           color);
      circle(cflowmap, Point(x, y), 2, color, -1);
    }
}